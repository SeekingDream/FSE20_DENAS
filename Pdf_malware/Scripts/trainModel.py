import keras
import numpy as np
import pickle as pickle
from keras.models import load_model
from keras.layers import Dense, Activation, Dropout, SimpleRNN, Embedding, Bidirectional,TimeDistributed




def createModel():
    model = keras.Sequential()

    model.add(Dense(200))
    model.add(Activation('relu'))
    model.add(Dropout(0.2))


    model.add(Dense(200))
    model.add(Activation('relu'))
    model.add(Dropout(0.2))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss=keras.losses.binary_crossentropy,
                  optimizer=keras.optimizers.Adadelta(),
                  metrics=['accuracy'])

    return model


def Normalization(X):
    X[np.nonzero(X)] = 1
    return X


def loaddata(filepath = "..\\data\\train_model_data.pkl"):
    f = open(filepath,"rb")
    data = pickle.load(f)
    X = data[0]
    y = data[1]

    X = Normalization(X)

    return X, y


def main():
    X, y = loaddata()
    model = createModel()
    train_y = np.int32(y[:, 0])
    #train_y = to_categorical(train_y)
    model.fit(X, train_y, batch_size= 50, validation_split=0.1, epochs=20, )
    model.save('..\\model\\MLP_model.h5')
    print("finish train model")



def testModel():
    model = load_model("..\\model\\MLP_model.h5")
    X, y = loaddata("..\\data\\test_model_data.pkl")

    pred_y = np.int32(model.predict(X) > 0.5)
    y = y[:,0]
    pred_y = pred_y.reshape([np.size(pred_y)])

    Y_Y = np.sum((y == 1) * (pred_y == 1))
    Y_N = np.sum((y == 1) * (pred_y == 0))
    N_Y = np.sum((y == 0) * (pred_y == 1))
    N_N = np.sum((y == 0) * (pred_y == 0))
    print("precision :", Y_Y / (Y_Y + N_Y))
    print("recall :", Y_Y / (Y_Y + Y_N))
    print("acc :", (N_N + Y_Y)/ (len(y)))


if __name__ == '__main__':
    #main()
    testModel()